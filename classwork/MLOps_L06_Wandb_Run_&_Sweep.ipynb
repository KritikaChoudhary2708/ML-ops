{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TGj3ctwAORC"
      },
      "source": [
        "#Install & Set Up Wandb\n",
        "To manage AI model development. Features include training, fine-tuning, reporting, automating hyperparameter sweeps, and utilizing the model registry for versioning and reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrC_C-b5ALoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3e3890-6c0a-4968-ba9b-ef42f923c807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.24.1)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.24.2-py3-none-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.46)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (26.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.51.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2026.1.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading wandb-0.24.2-py3-none-manylinux_2_28_x86_64.whl (23.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wandb\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.24.1\n",
            "    Uninstalling wandb-0.24.1:\n",
            "      Successfully uninstalled wandb-0.24.1\n",
            "Successfully installed wandb-0.24.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_USBaWtbg_q"
      },
      "source": [
        " Login to Wandb\n",
        "\n",
        "Authenticate with your Wandb account:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs_NOnFMAZxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d52e9f2-81dd-497b-9b9c-6d14d91a7095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create a new API key at: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Store your API key securely and do not share it.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste your API key and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhardik-jain\u001b[0m (\u001b[33mhardik-jain-iit-jodhpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzmN3kIQAk4c"
      },
      "source": [
        "#Initialize a Wandb Run\n",
        "Create a Wandb project to track experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXjxr8DVAlYR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0e5f20c5-2664-429a-dd2b-e2bee48d278d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260208_113528-634if80x</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/634if80x' target=\"_blank\">peach-dew-1</a></strong> to <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/634if80x' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/634if80x</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=\"MLOps-L06-image-classification\",  # Change project name as needed\n",
        "    config={\n",
        "        \"lr\": 0.001,\n",
        "        \"epochs\": 5,\n",
        "        \"batch_size\": 64,\n",
        "        \"model_type\": \"CNN\",\n",
        "    }\n",
        ")\n",
        "config = wandb.config  # Retrieve experiment config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5l4km1JDGkS"
      },
      "source": [
        " Load CIFAR-10 Dataset\n",
        "\n",
        "*   We load CIFAR-10 and normalize it for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFrQ8lJODRaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9880e4c-1993-4c8b-a6cf-dff15f66de0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 80.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Transform: Convert images to tensors and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load training & test data\n",
        "train_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=config.batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZXSoOEBcBnG"
      },
      "source": [
        "Define a CNN Model\n",
        "\n",
        "We create a simple Convolutional Neural Network (CNN) for image classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_ablF-9CaYc"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 32 * 8 * 8)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvJJEO8SDmcf"
      },
      "source": [
        "Train & Log Metrics in WandB\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Cz8CrKQEA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "44aacbac-c9e4-4823-a1d8-53ceee850b6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peach-dew-1</strong> at: <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/634if80x' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/634if80x</a><br> View project at: <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260208_113528-634if80x/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260208_113738-shgoevhf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/shgoevhf' target=\"_blank\">honest-cloud-2</a></strong> to <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/shgoevhf' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/shgoevhf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Data passed to `wandb.Image` should consist of values in the range [0, 255], image data will be normalized to this range, but behavior will be removed in a future version of wandb.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m You are mutating a Table with log_mode='IMMUTABLE' that has been logged already. Subsequent log() calls will have no effect. Set log_mode='MUTABLE' to enable re-logging after mutations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>test_accuracy</td><td>▁▅▇▇█</td></tr><tr><td>training_loss</td><td>█▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>68.88</td></tr><tr><td>training_loss</td><td>0.77126</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">honest-cloud-2</strong> at: <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/shgoevhf' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/runs/shgoevhf</a><br> View project at: <a href='https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification' target=\"_blank\">https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification</a><br>Synced 5 W&B file(s), 1 media file(s), 10004 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260208_113738-shgoevhf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "\n",
        "def train_model(config_dict):\n",
        "    wandb.init(project=\"MLOps-L06-image-classification\", config=config_dict)\n",
        "    config = dict(wandb.config)  # Safe way to access config values\n",
        "\n",
        "    model = SimpleCNN()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    table = wandb.Table(columns=[\"Image\", \"True Label\", \"Predicted Label\"])\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                wandb.log({\"training_loss\": running_loss / 100, \"epoch\": epoch + 1})\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                for i in range(images.size(0)):\n",
        "                    img = wandb.Image(images[i])\n",
        "                    table.add_data(img, labels[i].item(), predicted[i].item())\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        wandb.log({\"test_accuracy\": accuracy, \"epoch\": epoch + 1, \"Live Predictions\": table})\n",
        "\n",
        "    # Save and log model\n",
        "    torch.save(model.state_dict(), \"model.pth\")\n",
        "    artifact = wandb.Artifact(\"simple_cnn_model\", type=\"model\")\n",
        "    artifact.add_file(\"model.pth\")\n",
        "    wandb.log_artifact(artifact)\n",
        "    wandb.finish()\n",
        "\n",
        "# Example configuration dictionary\n",
        "config = {\n",
        "    \"lr\": 0.001,\n",
        "    \"epochs\": 5\n",
        "}\n",
        "\n",
        "train_model(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1g-TRlqF06Y"
      },
      "source": [
        "# Hyperparameter Optimization with Sweeps\n",
        "\n",
        "To automate hyperparameter search and visualize rich, interactive experiment tracking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74WooZDFF1ey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9a417a-cfcc-4b61-f55e-2c0694b8fc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: nmj0tkdd\n",
            "Sweep URL: https://wandb.ai/hardik-jain-iit-jodhpur/MLOps-L06-image-classification/sweeps/nmj0tkdd\n"
          ]
        }
      ],
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"grid\",  # Options: \"random\", \"grid\", \"bayes\"\n",
        "    \"metric\": {\"name\": \"test_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"lr\": {\"values\": [0.001, 0.0005, 0.0001]},\n",
        "        \"epochs\": {\"values\": [5, 10]},\n",
        "    },\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"MLOps-L06-image-classification\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz9wR3tUHPR3"
      },
      "source": [
        "Define Sweep Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3YfnqlNHQFk"
      },
      "outputs": [],
      "source": [
        "def sweep_train():\n",
        "    with wandb.init() as run:\n",
        "        config = run.config  # Load sweep-config parameters\n",
        "\n",
        "        model = SimpleCNN()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "        best_accuracy = 0.0  # Track the highest accuracy\n",
        "        best_model_path = \"best_model.pth\"  # File to store the best model\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            model.train(True)\n",
        "            running_loss = 0.0\n",
        "\n",
        "            for i, (inputs, labels) in enumerate(train_loader):\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                if i % 100 == 99:\n",
        "                    wandb.log({\"training_loss\": running_loss / 100, \"epoch\": epoch + 1})\n",
        "                    running_loss = 0.0\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            correct, total = 0, 0\n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader:\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "            wandb.log({\"test_accuracy\": accuracy, \"epoch\": epoch + 1})\n",
        "\n",
        "            # Save model if it's the best so far\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                torch.save(model.state_dict(), best_model_path)  # Save locally\n",
        "\n",
        "        # Log the best model as a Wandb artifact\n",
        "        artifact = wandb.Artifact(\"best_model\", type=\"model\")\n",
        "        artifact.add_file(best_model_path)\n",
        "        wandb.log_artifact(artifact)\n",
        "\n",
        "        wandb.finish()  # Close Wandb properly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWizaKR-cunm"
      },
      "source": [
        "Run the Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4Z-2bYmkhM8"
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id, function=sweep_train, count=3)  # Runs 3 experiments"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}