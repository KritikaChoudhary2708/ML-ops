{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ulBiYO8sgLD"
      },
      "source": [
        "# Create a simple tensor with random items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjhe9izssgLF",
        "outputId": "8f711272-dc9c-421d-8844-128bebcac444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[144.98 -43.02   0.   -15.28  28.86 127.93  29.88 -42.02  96.57 103.79\n",
            "  -6.5  106.55  -4.28  -5.7  -19.36  -1.78  73.15 -23.7  -21.38 143.98]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Suppress scientific notation\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Generate randomly distributed parameters\n",
        "params = np.random.uniform(low=-50, high=150, size=20)\n",
        "\n",
        "# Make sure important values are at the beginning for better debugging\n",
        "params[0] = params.max() + 1\n",
        "params[1] = params.min() - 1\n",
        "params[2] = 0\n",
        "\n",
        "# Round each number to the second decimal place\n",
        "params = np.round(params, 2)\n",
        "\n",
        "# Print the parameters\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeKhDVWAsgLH"
      },
      "source": [
        "# Define the quantization methods and quantize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phSoSB7YsgLH"
      },
      "outputs": [],
      "source": [
        "def clamp(params_q: np.array, lower_bound: int, upper_bound: int) -> np.array:\n",
        "    params_q[params_q < lower_bound] = lower_bound\n",
        "    params_q[params_q > upper_bound] = upper_bound\n",
        "    return params_q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def asymmetric_quantization(params: np.array, bits: int) -> tuple[np.array, float, int]:\n",
        "    # Calculate the scale and zero point\n",
        "    alpha = np.max(params)\n",
        "    beta = np.min(params)\n",
        "    scale = (alpha - beta) / (2**bits-1)\n",
        "    zero = -1*np.round(beta / scale)\n",
        "    lower_bound, upper_bound = 0, 2**bits-1\n",
        "    # Quantize the parameters\n",
        "    quantized = clamp(np.round(params / scale + zero), lower_bound, upper_bound).astype(np.int32)\n",
        "    return quantized, scale, zero\n",
        "\n",
        "def asymmetric_dequantize(params_q: np.array, scale: float, zero: int) -> np.array:\n",
        "    return (params_q - zero) * scale\n",
        "\n",
        "(asymmetric_q, asymmetric_scale, asymmetric_zero) = asymmetric_quantization(params, 8)\n",
        "print(f'Original:')\n",
        "print(np.round(params, 2))\n",
        "print('')\n",
        "print(f'Asymmetric scale: {asymmetric_scale}, zero: {asymmetric_zero}')\n",
        "print(asymmetric_q)"
      ],
      "metadata": {
        "id": "XKBzwlqEnzNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0c7258-050d-49dd-c53a-0358a9c7cbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "[144.98 -43.02   0.   -15.28  28.86 127.93  29.88 -42.02  96.57 103.79\n",
            "  -6.5  106.55  -4.28  -5.7  -19.36  -1.78  73.15 -23.7  -21.38 143.98]\n",
            "\n",
            "Asymmetric scale: 0.7372549019607844, zero: 58.0\n",
            "[255   0  58  37  97 232  99   1 189 199  49 203  52  50  32  56 157  26\n",
            "  29 253]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def symmetric_quantization(params: np.array, bits: int) -> tuple[np.array, float]:\n",
        "    # Calculate the scale\n",
        "    alpha = np.max(np.abs(params))\n",
        "    scale = alpha / (2**(bits-1)-1)\n",
        "    lower_bound = -2**(bits-1)\n",
        "    upper_bound = 2**(bits-1)-1\n",
        "    # Quantize the parameters\n",
        "    quantized = clamp(np.round(params / scale), lower_bound, upper_bound).astype(np.int32)\n",
        "    return quantized, scale\n",
        "\n",
        "def symmetric_dequantize(params_q: np.array, scale: float) -> np.array:\n",
        "    return params_q * scale\n",
        "\n",
        "(symmetric_q, symmetric_scale) = symmetric_quantization(params, 8)\n",
        "\n",
        "print(f'Original:')\n",
        "print(np.round(params, 2))\n",
        "print('')\n",
        "print(f'Symmetric scale: {symmetric_scale}')\n",
        "print(symmetric_q)"
      ],
      "metadata": {
        "id": "h6nXso9KnsWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb78b6e-2ebc-4523-b38d-ed032acaface"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "[144.98 -43.02   0.   -15.28  28.86 127.93  29.88 -42.02  96.57 103.79\n",
            "  -6.5  106.55  -4.28  -5.7  -19.36  -1.78  73.15 -23.7  -21.38 143.98]\n",
            "\n",
            "Symmetric scale: 1.1415748031496062\n",
            "[127 -38   0 -13  25 112  26 -37  85  91  -6  93  -4  -5 -17  -2  64 -21\n",
            " -19 126]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quantization_error(params: np.array, params_q_dq: np.array):\n",
        "    # calculate the MSE\n",
        "    return np.mean((params - params_q_dq)**2)"
      ],
      "metadata": {
        "id": "6FSuAeGLnuo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR2WZBPpsgLH",
        "outputId": "1fc220ea-ed81-4424-9141-cddc0f401380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "[144.98 -43.02   0.   -15.28  28.86 127.93  29.88 -42.02  96.57 103.79\n",
            "  -6.5  106.55  -4.28  -5.7  -19.36  -1.78  73.15 -23.7  -21.38 143.98]\n",
            "\n",
            "Dequantize Asymmetric:\n",
            "[145.24 -42.76   0.   -15.48  28.75 128.28  30.23 -42.02  96.58 103.95\n",
            "  -6.64 106.9   -4.42  -5.9  -19.17  -1.47  72.99 -23.59 -21.38 143.76]\n",
            "\n",
            "Dequantize Symmetric:\n",
            "[144.98 -43.38   0.   -14.84  28.54 127.86  29.68 -42.24  97.03 103.88\n",
            "  -6.85 106.17  -4.57  -5.71 -19.41  -2.28  73.06 -23.97 -21.69 143.84]\n"
          ]
        }
      ],
      "source": [
        "# Dequantize the parameters back to 32 bits\n",
        "params_deq_asymmetric = asymmetric_dequantize(asymmetric_q, asymmetric_scale, asymmetric_zero)\n",
        "params_deq_symmetric = symmetric_dequantize(symmetric_q, symmetric_scale)\n",
        "\n",
        "print(f'Original:')\n",
        "print(np.round(params, 2))\n",
        "print('')\n",
        "print(f'Dequantize Asymmetric:')\n",
        "print(np.round(params_deq_asymmetric,2))\n",
        "print('')\n",
        "print(f'Dequantize Symmetric:')\n",
        "print(np.round(params_deq_symmetric, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2MPTlPisgLI",
        "outputId": "ce2af06d-66ea-429e-acc9-1a7eb4ff7b6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Asymmetric error: 0.04\n",
            "   Symmetric error: 0.08\n"
          ]
        }
      ],
      "source": [
        "# Calculate the quantization error\n",
        "print(f'{\"Asymmetric error: \":>20}{np.round(quantization_error(params, params_deq_asymmetric), 2)}')\n",
        "print(f'{\"Symmetric error: \":>20}{np.round(quantization_error(params, params_deq_symmetric), 2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-Training Quantization (PTQ)"
      ],
      "metadata": {
        "id": "EEvUqXXKoSka"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6VaAb3FsgLI",
        "outputId": "c583865d-301b-4a7f-8257-5013cc49e772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Prediction (top-1 index): 644\n",
            "PTQ Model Prediction (top-1 index): 644\n",
            "\n",
            "Quantization Error (MSE): 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-372910766.py:13: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_ptq = torch.quantization.quantize_dynamic(model_fp32, {torch.nn.Linear}, dtype=torch.qint8)\n"
          ]
        }
      ],
      "source": [
        "# Post-Training Quantization (PTQ) Example using PyTorch and inbuilt image\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import FakeData\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load a pretrained model\n",
        "model_fp32 = models.mobilenet_v2(pretrained=True).eval()\n",
        "\n",
        "# Apply dynamic quantization to linear layers\n",
        "model_ptq = torch.quantization.quantize_dynamic(model_fp32, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "# Create fake image data (inbuilt dataset)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "fake_dataset = FakeData(size=1, image_size=(3, 224, 224), transform=transform)\n",
        "fake_loader = DataLoader(fake_dataset, batch_size=1)\n",
        "\n",
        "# Get one sample\n",
        "input_tensor, _ = next(iter(fake_loader))\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    output_fp32 = model_fp32(input_tensor)\n",
        "    output_ptq = model_ptq(input_tensor)\n",
        "\n",
        "print(\"Original Model Prediction (top-1 index):\", torch.argmax(output_fp32, dim=1).item())\n",
        "print(\"PTQ Model Prediction (top-1 index):\", torch.argmax(output_ptq, dim=1).item())\n",
        "\n",
        "# Calculate quantization error (using Mean Squared Error)\n",
        "quantization_error = F.mse_loss(output_fp32, output_ptq)\n",
        "print(f\"\\nQuantization Error (MSE): {quantization_error.item():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "probability-statistics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}